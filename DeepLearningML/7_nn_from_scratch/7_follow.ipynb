{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db137b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6851d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('insurance_data.csv')\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[['age','affordibility']],df.bought_insurance,test_size=0.2,random_state=25)\n",
    "x_train_scaled = x_train.copy() #copy() makes rerun this block wont calculate new ans\n",
    "x_train_scaled['age'] = x_train_scaled['age']/100\n",
    "x_test_scaled = x_test.copy()\n",
    "x_test_scaled['age'] = x_test_scaled['age']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2108ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNN():\n",
    "    def __init__(self):\n",
    "        self.w1 = 1\n",
    "        self.w2 = 1\n",
    "        self.bias = 0\n",
    "    \n",
    "    def fit(self, x ,y, epochs, loss_threshold):\n",
    "        self.w1, self.w2, self.bias = self.gradient_descent(x['age'], x['affordibility'], y, epochs, loss_threshold)\n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        weighted_sum = self.w1*x_test['age'] + self.w2*x_test['affordibility'] + self.bias\n",
    "        return self.sigmoid_numpy(weighted_sum)\n",
    "    \n",
    "    def sigmoid_numpy(self, x): #take array as well\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def log_loss(self, y_true, y_predicted):\n",
    "        epsilon = 1e-15\n",
    "        y_predicted_new = [max(i,epsilon) for i in y_predicted]\n",
    "        y_predicted_new = [min(i,1-epsilon) for i in y_predicted_new]\n",
    "        y_predicted_new = np.array(y_predicted_new)\n",
    "        return -np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))\n",
    "\n",
    "    def gradient_descent(self, age, affordibility, y_true, epochs, loss_threshold):\n",
    "        #w1, w2, bias\n",
    "        w1 = w2 = 1\n",
    "        bias = 0\n",
    "        learning_rate = 0.5\n",
    "        n = len(age)\n",
    "        for i in range(epochs):\n",
    "            weighted_sum = w1*age + w2*affordibility + bias\n",
    "            y_pred = self.sigmoid_numpy(weighted_sum)\n",
    "            #shape(22,)\n",
    "\n",
    "            loss = self.log_loss(y_true,y_pred)\n",
    "\n",
    "            w1d = (1/n)*np.dot(age,(y_pred-y_true))\n",
    "                               #shape(22,)\n",
    "            w2d = (1/n)*np.dot(affordibility,(y_pred-y_true))\n",
    "                               #shape(22,)       \n",
    "            bias_d = np.mean(y_pred-y_true)\n",
    "\n",
    "            w1 = w1 - learning_rate*w1d\n",
    "            w2 = w2 - learning_rate*w2d\n",
    "            bias = bias - learning_rate*bias_d\n",
    "            \n",
    "            if (i+1)%100==0:\n",
    "                print(f'Epoch:{i+1}, w1:{w1}, w2:{w2}, bias:{bias}, loss:{loss}')\n",
    "\n",
    "            if loss <= loss_threshold:\n",
    "                print(f'Epoch:{i+1}, w1:{w1}, w2:{w2}, bias:{bias}, loss:{loss}')\n",
    "\n",
    "                break\n",
    "\n",
    "        return w1, w2, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f36dfa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100, w1:2.1871944491052364, w2:1.2918774898345378, bias:-1.6533819823304428, loss:0.5395530569489538\n",
      "Epoch:200, w1:3.4316889691263146, w2:1.4037274192103975, bias:-2.252091504673362, loss:0.5008101251292182\n",
      "Epoch:300, w1:4.462839550361659, w2:1.4385080284751603, bias:-2.703328362713941, loss:0.4752896446882009\n",
      "Epoch:367, w1:5.051047623653049, w2:1.4569794548473887, bias:-2.9596534546250037, loss:0.46293944095888917\n"
     ]
    }
   ],
   "source": [
    "customModel = myNN()\n",
    "customModel.fit(x_train_scaled, y_train, epochs=8000, loss_threshold=0.4631)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8812bd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     0.705020\n",
       "10    0.355836\n",
       "21    0.161599\n",
       "11    0.477919\n",
       "14    0.725586\n",
       "9     0.828987\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customModel.predict(x_test_scaled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
